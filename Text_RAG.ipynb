{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG) with Llama3 8B\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/togethercomputer/together-cookbook/blob/main/Text_RAG.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "For AI models to be effective in specialized tasks, they often require domain-specific knowledge. For instance, a financial advisory chatbot needs to understand market trends and products offered by a specific bank, while an AI legal assistant must be equipped with knowledge of statutes, regulations, and past case law.\n",
    "\n",
    "A common solution is Retrieval-Augmented Generation (RAG), which retrieves relevant data from a knowledge base and combines it with the userâ€™s prompt, thereby improving and customizing the model's output to the provided data.\n",
    "\n",
    "<img src=\"images/simple_RAG.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Explanation\n",
    "\n",
    "RAG operates by preprocessing a large knowledge base and dynamically retrieving relevant information at runtime.\n",
    "\n",
    "Here's a breakdown of the process:\n",
    "\n",
    "1. Indexing the Knowledge Base:\n",
    "The corpus (collection of documents) is divided into smaller, manageable chunks of text. Each chunk is converted into a vector embedding using an embedding model. These embeddings are stored in a vector database optimized for similarity searches.\n",
    "\n",
    "2. Query Processing and Retrieval:\n",
    "When a user submits a prompt that would initially go directly to a LLM we process that and extract a query, the system searches the vector database for chunks semantically similar to the query. The most relevant chunks are retrieved and injected into the prompt sent to the generative AI model.\n",
    "\n",
    "3. Response Generation:\n",
    "The AI model then uses the retrieved information along with its pre-trained knowledge to generate a response. Not only does this reduce the likelihood of hallucination since relevant context is provided directly in the prompt but it also allows us to cite to source material as well.\n",
    "\n",
    "<img src=\"images/text_RAG.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ubSQgZNalImb",
    "outputId": "536b046c-306e-490c-97d8-40a7dfdaba24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting together\n",
      "  Downloading together-1.3.4-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from together) (3.10.5)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from together) (8.1.7)\n",
      "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from together) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from together) (1.26.4)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from together) (10.4.0)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from together) (16.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from together) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from together) (2.32.3)\n",
      "Collecting rich<14.0.0,>=13.8.1 (from together)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from together) (4.66.5)\n",
      "Collecting typer<0.14,>=0.9 (from together)\n",
      "  Downloading typer-0.13.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.3->together) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\anaconda3\\lib\\site-packages (from click<9.0.0,>=8.1.7->together) (0.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.6.3->together) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.6.3->together) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.6.3->together) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->together) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->together) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->together) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->together) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.8.1->together) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.8.1->together) (2.15.1)\n",
      "Collecting shellingham>=1.3.0 (from typer<0.14,>=0.9->together)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.0)\n",
      "Downloading together-1.3.4-py3-none-any.whl (69 kB)\n",
      "Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading typer-0.13.0-py3-none-any.whl (44 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: shellingham, eval-type-backport, rich, typer, together\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.7.1\n",
      "    Uninstalling rich-13.7.1:\n",
      "      Successfully uninstalled rich-13.7.1\n",
      "Successfully installed eval-type-backport-0.2.0 rich-13.9.4 shellingham-1.5.4 together-1.3.4 typer-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YO3t0PAHlpaE"
   },
   "outputs": [],
   "source": [
    "import together, os\n",
    "from together import Together\n",
    "\n",
    "# Paste in your Together AI API Key or load it\n",
    "TOGETHER_API_KEY = os.environ.get(\"TOGETHER_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and View the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the movies dataset\n",
    "# !wget https://raw.githubusercontent.com/togethercomputer/together-cookbook/refs/heads/main/datasets/movies.json\n",
    "# !mkdir datasets\n",
    "# !mv movies.json datasets/movies.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2croRfETmD0s",
    "outputId": "a6e88271-b4e0-4ead-ced7-4905ae4ea442"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Minions',\n",
       "  'overview': 'Minions Stuart, Kevin and Bob are recruited by Scarlet Overkill, a super-villain who, alongside her inventor husband Herb, hatches a plot to take over the world.',\n",
       "  'director': 'Kyle Balda',\n",
       "  'genres': 'Family Animation Adventure Comedy',\n",
       "  'tagline': 'Before Gru, they had a history of bad bosses'},\n",
       " {'title': 'Interstellar',\n",
       "  'overview': 'Interstellar chronicles the adventures of a group of explorers who make use of a newly discovered wormhole to surpass the limitations on human space travel and conquer the vast distances involved in an interstellar voyage.',\n",
       "  'director': 'Christopher Nolan',\n",
       "  'genres': 'Adventure Drama Science Fiction',\n",
       "  'tagline': 'Mankind was born on Earth. It was never meant to die here.'},\n",
       " {'title': 'Deadpool',\n",
       "  'overview': 'Deadpool tells the origin story of former Special Forces operative turned mercenary Wade Wilson, who after being subjected to a rogue experiment that leaves him with accelerated healing powers, adopts the alter ego Deadpool. Armed with his new abilities and a dark, twisted sense of humor, Deadpool hunts down the man who nearly destroyed his life.',\n",
       "  'director': 'Tim Miller',\n",
       "  'genres': 'Action Adventure Comedy',\n",
       "  'tagline': 'Witness the beginning of a happy ending'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('./datasets/movies.json', 'r') as file:\n",
    "    movies_data = json.load(file)\n",
    "\n",
    "movies_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Retreival Pipeline - \"R\" part of RAG\n",
    "\n",
    "Below we implement a simple retreival pipeline:\n",
    "1. Embed movie documents + query\n",
    "2. Obtain top k movies ranked based on cosine similarities between the query and movie vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "I0o-ZpaDlsgZ"
   },
   "outputs": [],
   "source": [
    "# This function will be used to access the Together API to generate embeddings for the movie plots\n",
    "\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "def generate_embeddings(input_texts: List[str], model_api_string: str) -> List[List[float]]:\n",
    "    \"\"\"Generate embeddings from Together python library.\n",
    "\n",
    "    Args:\n",
    "        input_texts: a list of string input texts.\n",
    "        model_api_string: str. An API string for a specific embedding model of your choice.\n",
    "\n",
    "    Returns:\n",
    "        embeddings_list: a list of embeddings. Each element corresponds to the each input text.\n",
    "    \"\"\"\n",
    "    together_client = together.Together(api_key = TOGETHER_API_KEY)\n",
    "    outputs = together_client.embeddings.create(\n",
    "        input=input_texts,\n",
    "        model=model_api_string,\n",
    "    )\n",
    "    return np.array([x.embedding for x in outputs.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwk2bwNGl84p",
    "outputId": "46797774-5d73-412a-db76-ee5e0d94ac85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Minions Minions Stuart, Kevin and Bob are recruited by Scarlet Overkill, a super-villain who, alongside her inventor husband Herb, hatches a plot to take over the world. Kyle Balda',\n",
       " 'Interstellar Interstellar chronicles the adventures of a group of explorers who make use of a newly discovered wormhole to surpass the limitations on human space travel and conquer the vast distances involved in an interstellar voyage. Christopher Nolan',\n",
       " 'Deadpool Deadpool tells the origin story of former Special Forces operative turned mercenary Wade Wilson, who after being subjected to a rogue experiment that leaves him with accelerated healing powers, adopts the alter ego Deadpool. Armed with his new abilities and a dark, twisted sense of humor, Deadpool hunts down the man who nearly destroyed his life. Tim Miller',\n",
       " 'Guardians of the Galaxy Light years from Earth, 26 years after being abducted, Peter Quill finds himself the prime target of a manhunt after discovering an orb wanted by Ronan the Accuser. James Gunn',\n",
       " \"Mad Max: Fury Road An apocalyptic story set in the furthest reaches of our planet, in a stark desert landscape where humanity is broken, and most everyone is crazed fighting for the necessities of life. Within this world exist two rebels on the run who just might be able to restore order. There's Max, a man of action and a man of few words, who seeks peace of mind following the loss of his wife and child in the aftermath of the chaos. And Furiosa, a woman of action and a woman who believes her path to survival may be achieved if she can make it across the desert back to her childhood homeland. George Miller\",\n",
       " 'Jurassic World Twenty-two years after the events of Jurassic Park, Isla Nublar now features a fully functioning dinosaur theme park, Jurassic World, as originally envisioned by John Hammond. Colin Trevorrow',\n",
       " \"Pirates of the Caribbean: The Curse of the Black Pearl Jack Sparrow, a freewheeling 17th-century pirate who roams the Caribbean Sea, butts heads with a rival pirate bent on pillaging the village of Port Royal. When the governor's daughter is kidnapped, Sparrow decides to help the girl's love save her. But their seafaring mission is hardly simple. Gore Verbinski\",\n",
       " 'Dawn of the Planet of the Apes A group of scientists in San Francisco struggle to stay alive in the aftermath of a plague that is wiping out humanity, while Caesar tries to maintain dominance over his community of intelligent apes. Matt Reeves',\n",
       " 'The Hunger Games: Mockingjay - Part 1 Katniss Everdeen reluctantly becomes the symbol of a mass rebellion against the autocratic Capitol. Francis Lawrence',\n",
       " 'Big Hero 6 The special bond that develops between plus-sized inflatable robot Baymax, and prodigy Hiro Hamada, who team up with a group of friends to form a band of high-tech heroes. Chris Williams']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the title, overview, and tagline of each movie\n",
    "# this makes the text that will be embedded for each movie more informative\n",
    "# as a result the embeddings will be richer and capture this information.\n",
    "\n",
    "to_embed = []\n",
    "for movie in movies_data[:1000]:\n",
    "    text = ''\n",
    "    for field in ['title', 'overview', 'director']:\n",
    "        value = movie.get(field, '')\n",
    "        text += str(value) + ' '\n",
    "    to_embed.append(text.strip())\n",
    "\n",
    "to_embed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "QMqmezr8mCUG"
   },
   "outputs": [],
   "source": [
    "# Use bge-base-en-v1.5 model to generate embeddings\n",
    "embeddings = generate_embeddings(to_embed, 'BAAI/bge-base-en-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "g1HTX3bGmYCk"
   },
   "outputs": [],
   "source": [
    "# Generate the vector embeddings for the query\n",
    "query = \"Popular movies directed by Christopher Nolan\"\n",
    "\n",
    "query_embedding = generate_embeddings([query], 'BAAI/bge-base-en-v1.5')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "eqQe4VsBmp7w"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate cosine similarity between the query embedding and each movie embedding\n",
    "similarity_scores = cosine_similarity([query_embedding], embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coKcFNlzmsrh",
    "outputId": "2ee108a4-e98d-4c6f-b09e-4eb009ed6e2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We get a similarity score for each of our 1000 movies - the higher the score, the more similar the movie is to the query\n",
    "similarity_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "0rvxmdvKmuhY"
   },
   "outputs": [],
   "source": [
    "# Get the indices of the highest to lowest values\n",
    "indices = np.argsort(-similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3m0zGxlLm1Zp",
    "outputId": "0c2c5d55-ed80-4b8e-ce56-f2750d308dea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Prestige',\n",
       " 'Interstellar',\n",
       " 'Inception',\n",
       " 'Insomnia',\n",
       " 'Snatch',\n",
       " 'The Dark Knight',\n",
       " 'Kingdom of Heaven',\n",
       " 'Memento',\n",
       " 'Saving Private Ryan',\n",
       " 'Bruce Almighty']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_sorted_titles = [movies_data[index]['title'] for index in indices[0]][:10]\n",
    "\n",
    "top_10_sorted_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreiver Function\n",
    "\n",
    "Once we understand the steps in the retriever pipeline above we can simplify it into the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "R6GLqD9_m2WN"
   },
   "outputs": [],
   "source": [
    "def retrieve(query: str, top_k: int = 5, index: np.ndarray = None) -> List[int]:\n",
    "    \"\"\"\n",
    "    Retrieve the top-k most similar items from an index based on a query.\n",
    "    Args:\n",
    "        query (str): The query string to search for.\n",
    "        top_k (int, optional): The number of top similar items to retrieve. Defaults to 5.\n",
    "        index (np.ndarray, optional): The index array containing embeddings to search against. Defaults to None.\n",
    "    Returns:\n",
    "        List[int]: A list of indices corresponding to the top-k most similar items in the index.\n",
    "    \"\"\"\n",
    "    \n",
    "    query_embedding = generate_embeddings([query], 'BAAI/bge-base-en-v1.5')[0]\n",
    "    similarity_scores = cosine_similarity([query_embedding], index)\n",
    "\n",
    "    return np.argsort(-similarity_scores)[0][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJ989oVqnrW-",
    "outputId": "9b63fd61-fd3a-4c97-b1c7-faddc54b7d47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([188,   1,  15, 692, 400], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve(\"Popular movies directed by Christopher Nolan\", top_k=5, index = embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Step - \"G\" part of RAG\n",
    "\n",
    "Below we will inject/augment the information the retreival pipeline extracts into the prompt to the Llama3 8b Model. \n",
    "\n",
    "This will help guide the generation by grounding it from facts in our knowledge base!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "YLoZYcx9nvAZ"
   },
   "outputs": [],
   "source": [
    "# Extract out the titles and overviews of the top 10 most similar movies\n",
    "titles = [movies_data[index]['title'] for index in indices[0]][:10]\n",
    "overviews = [movies_data[index]['overview'] for index in indices[0]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTuUW3HOn_AA",
    "outputId": "65909533-a0f4-45f2-bfe2-021c94d75aac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a fascinating challenge! Here's a story that connects each of these movies into a single, sprawling narrative:\n",
      "\n",
      "In the world of \"The Prestige,\" two magicians, Angier and Borden, are locked in a bitter rivalry that spans decades. Their obsession with outdoing each other leads them to experiment with the boundaries of reality, pushing the limits of what is possible.\n",
      "\n",
      "Meanwhile, in the world of \"Interstellar,\" a team of scientists and explorers, led by Professor Brand, are on a mission to find a new home for humanity as Earth faces an impending environmental disaster. Their journey takes them through a wormhole, where they encounter strange phenomena and alternate realities.\n",
      "\n",
      "As they navigate the vast distances of space, they stumble upon a mysterious, ancient artifact that holds the key to manipulating reality. This artifact, known as the \"Chrono-Crystal,\" is coveted by both Angier and Borden, who see its power as the ultimate tool in their rivalry.\n",
      "\n",
      "In \"Inception,\" Cobb, a skilled thief, is hired by a wealthy businessman to plant an idea in the mind of a rival CEO. Cobb's team, including Arthur, Ariadne, and Eames, use the Chrono-Crystal to enter the target's subconscious, where they must navigate the blurred lines between reality and dreams.\n",
      "\n",
      "However, their mission is compromised when they are pursued by a group of rogue agents, led by the enigmatic Mal, who seek to use the Chrono-Crystal for their own nefarious purposes. This group is revealed to be connected to the world of \"Memento,\" where Leonard Shelby, a man suffering from short-term memory loss, is on a quest to avenge his wife's murder.\n",
      "\n",
      "As Leonard's search for justice takes him deeper into the world of organized crime, he becomes entangled in a web of deceit and corruption that reaches the highest echelons of power. He discovers that the Chrono-Crystal is being used by a powerful crime lord, who seeks to manipulate reality to further his own interests.\n",
      "\n",
      "In \"Saving Private Ryan,\" a group of soldiers, led by Captain Miller, are tasked with rescuing a young man, Private Ryan, who is trapped behind enemy lines during World War II. As they navigate the treacherous landscape of war, they stumble upon a mysterious, ancient artifact that holds the key to the Chrono-Crystal's power.\n",
      "\n",
      "Meanwhile, in \"Bruce Almighty,\" Bruce Nolan, a down-on-his-luck TV reporter, is granted godlike powers by God himself. Bruce uses his newfound abilities to manipulate reality, but soon finds himself struggling to maintain control over his newfound powers.\n",
      "\n",
      "As Bruce's powers grow stronger, he becomes aware of the Chrono-Crystal's existence and its connection to the world of magic and reality manipulation. He realizes that the Crystal is the key to unlocking the secrets of the universe and that he must use his powers to prevent it from falling into the wrong hands.\n",
      "\n",
      "In the climactic final battle, Bruce, with the help of his friends and allies, must confront the forces of darkness and chaos that seek to exploit the Chrono-Crystal's power. Along the way, he must also confront his own demons and learn to wield his powers responsibly.\n",
      "\n",
      "In the end, Bruce emerges victorious, but not without scars. He realizes that the power of the Chrono-Crystal is too great for any one person to wield and that it must be protected and used for the greater good.\n",
      "\n",
      "The story concludes with Bruce, now wiser and more humble, using his powers to help those in need and to protect the world from those who would misuse the Chrono-Crystal's power. The movie ends with a sense of hope and renewal, as Bruce looks out upon a brighter future, knowing that he has been given a second chance to make a difference.\n",
      "\n",
      "And so, the story of \"The Prestige,\" \"Interstellar,\" \"Inception,\" \"Insomnia,\" \"Snatch,\" \"The Dark Knight,\" \"Kingdom of Heaven,\" \"Memento,\" \"Saving Private Ryan,\" and \"Bruce Almighty\" comes full circle, weaving together a complex tapestry of magic, reality, and the human condition.\n"
     ]
    }
   ],
   "source": [
    "client = Together(api_key = TOGETHER_API_KEY)\n",
    "\n",
    "# Generate a story based on the top 10 most similar movies\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3-8b-chat-hf\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a academy award winning screenwriter. Given only the overview of different plots you can create a plot that connects each of the movies into a single multi-verse.\"},\n",
    "      {\"role\": \"user\", \"content\": f\"Tell me a story about {titles}. Here is some information about them {overviews}\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see a simple RAG pipeline where we use semantic search to perform retreival and pass relevant information into the prompt of a LLM to condition its generation.\n",
    "\n",
    "To learn more about the Together AI API please refer to the [docs here](https://docs.together.ai/docs/introduction)!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
